# ðŸ¦ BankChurn Predictor

**Sistema de predicciÃ³n de abandono de clientes bancarios con machine learning avanzado y manejo de clases desbalanceadas**
[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-1.0+-orange.svg)](https://scikit-learn.org)
[![F1-Score](https://img.shields.io/badge/F1--Score-0.637-green.svg)](EXECUTIVE_SUMMARY.md)
[![AUC-ROC](https://img.shields.io/badge/AUC--ROC-0.867-brightgreen.svg)](EXECUTIVE_SUMMARY.md)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

## TÃ­tulo + 1 lÃ­nea elevator (problema y valor).
BankChurn Predictor â€” Clasificador de churn bancario que prioriza clientes en riesgo para campaÃ±as de retenciÃ³n, con pipeline reproducible y API lista para demo.

## TL;DR â€” CÃ³mo ejecutar demo en 3 pasos (comandos concretos).
1. `make install` 
2. `make train`   # entrena y guarda modelo en `models/` + mÃ©tricas en `results/` 
3. `make api-start` y `curl -s http://localhost:8000/health | jq`  # verifica API

## InstalaciÃ³n (dependencias core + cÃ³mo usar Docker demo).
- Local (core):
  - `python -m venv .venv && source .venv/bin/activate` 
  - `pip install -r requirements-core.txt` 
- Desarrollo / full (tests, MLflow, Evidently):
  - `pip install -r requirements.txt`  # incluye dev + monitorizaciÃ³n opcional
- Docker:
  - `docker build -t bankchurn-predictor .` 
  - `docker run -p 8000:8000 bankchurn-predictor` 

## Quickstart (ej: make demo o python -m main --mode demo) â€” entradas y salidas esperadas.
- Entrenamiento:
  - `python main.py --mode train --config configs/config.yaml --input data/raw/Churn.csv` 
  - Entrada: CSV con columnas estÃ¡ndar de Beta Bank en `data/raw/Churn.csv`.  
  - Salida: `models/best_model.pkl`, `models/model_v1.0.0.pkl`, `results/training_results.json`.
- EvaluaciÃ³n:
  - `python main.py --mode eval --config configs/config.yaml --input data/raw/Churn.csv` 
  - Salida: mÃ©tricas F1/ROC-AUC + matriz de confusiÃ³n en consola.
- PredicciÃ³n batch:
  - `python main.py --mode predict --config configs/config.yaml --input data/new_customers.csv --output predictions.csv` 
  - Salida: `predictions.csv` con `churn_prediction`, `churn_probability`, `risk_level`.
- API docs:
  - Tras `make api-start`, abre `http://localhost:8000/docs` para la documentaciÃ³n interactiva de FastAPI.

## VersiÃ³n actual (v1) â€” alcance real

- **Implementado en v1:**
  - CLI `train | eval | predict` vÃ­a `main.py`, parametrizada por `configs/config.yaml` y datasets en `data/`.
  - Modelo ensemble (LogReg + RandomForest) con manejo explÃ­cito de desbalance (resampling + class weights) y calibraciÃ³n de probabilidades.
  - Artefactos reproducibles: modelos en `models/`, mÃ©tricas y reports en `results/`, logs en `logs/`.
  - API FastAPI (`app/fastapi_app.py`) para inferencia online y scripts de monitoreo de drift en `monitoring/`.
  - Tests de datos/modelo/API/fairness en `tests/` y soporte para MLflow (modo local `file:./mlruns`).
- **Roadmap / contenido conceptual:**
  - Extensiones de interpretabilidad avanzada (p.ej. SHAP global/local) y workflows de retraining continuo se consideran trabajo futuro, apoyado por la estructura de `docs/` y las model/data cards.

## ðŸš€ Demo rÃ¡pida

Desde el directorio `BankChurn-Predictor/`:

```bash
# Instalar dependencias
make install

# Entrenar modelo y generar artifacts (models/, results/)
make train

# Levantar API de inferencia
make api-start

# Healthcheck
curl -s http://localhost:8000/health | jq

# PredicciÃ³n de ejemplo
curl -s -X POST http://localhost:8000/predict \
  -H 'Content-Type: application/json' \
  -d @app/example_payload.json | jq
```

### Demo con Docker

```bash
docker build -t bankchurn-predictor .
docker run -p 8000:8000 bankchurn-predictor
```

## Model card summary (objetivo, datos, mÃ©tricas clave, limitaciones).

- Objetivo: predecir `Exited` y priorizar clientes de alto riesgo.
- Datos: dataset sintÃ©tico Beta Bank (â‰ˆ10k clientes, fuerte desbalance 80/20), almacenado en `data/raw/Churn.csv`.
- MÃ©tricas tÃ­picas: F1â‰ˆ0.64, ROC-AUCâ‰ˆ0.87 (ejemplo educativo; ver `EXECUTIVE_SUMMARY.md` y `results/training_results.json`).
- Limitaciones: datos sintÃ©ticos, riesgo de sesgo por `Geography` y `Age`; no usar en producciÃ³n real sin recalibrar.

## ðŸ› ï¸ Stack tecnolÃ³gico

- **Lenguaje:** Python 3.8+.
- **ML:** scikit-learn (LogisticRegression, RandomForest, VotingClassifier), Optuna para hyperopt (modo avanzado).
- **MLOps / tracking:** MLflow (opcional, backend `file:./mlruns`), DVC para datos/pipelines (`dvc.yaml`).
- **API:** FastAPI + Uvicorn para servir el modelo empaquetado (`models/model_v1.0.0.pkl`).
- **Monitoreo:** scripts KS/PSI en `monitoring/` para evaluar drift de distribuciÃ³n.
- **Infraestructura:** Docker + `docker-compose.yml`, GitHub Actions para CI (pytest+cov, mypy, flake8).

## ðŸ“š DocumentaciÃ³n tÃ©cnica

Para detalles de arquitectura, pipeline y decisiones de diseÃ±o, ver:

- `docs/architecture.md` â€” componentes principales (BankChurnPredictor, ResampleClassifier, API FastAPI, monitoring, MLflow).
- `docs/training_pipeline.md` â€” flujo completo de entrenamiento/evaluaciÃ³n, estructura de `results/training_results.json` y criterios de mÃ©tricas.
- `model_card.md` â€” ficha del modelo (uso previsto, datos, performance, Ã©tica/fairness, SLOs).
- `data_card.md` â€” ficha del dataset (origen, distribuciÃ³n de clases, limitaciones y sesgos potenciales).
- `EXECUTIVE_SUMMARY.md` â€” resumen ejecutivo orientado a negocio/portafolio.

## Tests y CI (cÃ³mo correr tests).

- Local:
  - Instalar dependencias completas: `pip install -r requirements.txt` o `make install-dev`.
  - Ejecutar tests: `pytest --cov=. --cov-report=term-missing`.
- CI:
  - Workflow `.github/workflows/ci.yml` instala `requirements.txt` por proyecto y ejecuta `pytest --cov`, `mypy` y `flake8`.
  - Para este proyecto se ejecuta ademÃ¡s un smoke-train: `python main.py --mode train --config configs/config.yaml --seed 42 --input data/raw/Churn.csv`.

## Reproducibilidad (semillas)

- Puedes fijar la aleatoriedad con el flag CLI `--seed` en `main.py`:
  - Ejemplo: `python main.py --mode train --config configs/config.yaml --seed 123`.
- Si no pasas `--seed`, el helper comÃºn resuelve la semilla como:
  - `SEED` en variables de entorno (si estÃ¡ definida).
  - En caso contrario, `42` por defecto.
- En tests, `pytest` utiliza un fixture `deterministic_seed` (en `tests/conftest.py`) que fija la semilla en cada test con el siguiente orden:
  - `TEST_SEED` > `SEED` > `42`.

## MonitorizaciÃ³n y retraining (quÃ© existe y quÃ© no).

- Drift:
  - Script `monitoring/check_drift.py` con KS/PSI y reporte Evidently opcional.
  - Ejemplo: `python monitoring/check_drift.py --ref data/raw/Churn.csv --cur data/raw/Churn.csv --out-json results/drift.json --report-html results/drift_report.html` o `make check-drift`.
- MLflow (opcional):
  - Soporte local `file:./mlruns` a travÃ©s de `scripts/run_mlflow.py`.
  - Ejemplo: `make mlflow-demo` (requiere dependencias de `requirements.txt`).
- Retraining:
  - Manual vÃ­a `python main.py --mode train ...` o pipeline DVC (`dvc repro`).
  - No hay scheduler ni retraining automÃ¡tico incluido (roadmap integrarlo con cron/CI/CD).
- Uso responsable:
  - Dataset sintÃ©tico con posibles sesgos (`Geography`, `Age`); revisar `model_card.md`.
  - No usar el modelo como Ãºnica fuente de decisiÃ³n en contextos reales.

## Estructura del repo (breve).

- `main.py`: CLI `train|eval|predict|hyperopt`.
- `app/fastapi_app.py`: API de inferencia (`/health`, `/predict`, `/predict_batch`, `/docs`).
- `configs/config.yaml`: esquema de datos, hiperparÃ¡metros, rutas.
- `data/`: scripts de preprocesamiento y datasets (`data/raw/Churn.csv`, `data/processed/churn_processed.csv`).
- `monitoring/`: chequeo de drift KS/PSI + reporte Evidently opcional (`check_drift.py`).
- `tests/`: tests de datos, modelo, API y fairness.
- `docs/`, `model_card.md`, `data_card.md`, `EXECUTIVE_SUMMARY.md`: documentaciÃ³n tÃ©cnica y de negocio.

```text
BankChurn-Predictor/
â”œâ”€â”€ app/                  # API FastAPI y ejemplos de carga de modelo
â”œâ”€â”€ configs/              # ConfiguraciÃ³n YAML (paths, split, hiperparÃ¡metros)
â”œâ”€â”€ data/                 # Datos de entrada (p.ej. Churn.csv) y derivados
â”œâ”€â”€ docs/                 # DocumentaciÃ³n tÃ©cnica detallada (arquitectura, pipeline)
â”œâ”€â”€ monitoring/           # Scripts de chequeo de drift (KS/PSI, reports)
â”œâ”€â”€ notebooks/            # Notebooks de EDA, demo y presentaciÃ³n
â”œâ”€â”€ scripts/              # Scripts auxiliares (entrenamiento, MLflow, etc.)
â”œâ”€â”€ tests/                # Tests de datos, modelo, API y fairness
â”œâ”€â”€ main.py               # CLI principal (train | eval | predict | hyperopt)
â”œâ”€â”€ model_card.md         # Ficha del modelo (uso, mÃ©tricas, Ã©tica/fairness, SLOs)
â”œâ”€â”€ data_card.md          # Ficha del dataset (origen, sesgos, gobernanza)
â”œâ”€â”€ EXECUTIVE_SUMMARY.md  # Resumen ejecutivo orientado a negocio/portafolio
â”œâ”€â”€ requirements*.txt     # Dependencias core/avanzadas
â””â”€â”€ Dockerfile            # Imagen mÃ­nima para API de inferencia
```

## Contacto / autor / licencia.

- Autor: Duque Ortega Mutis (DuqueOM) â€” ver mÃ¡s contexto de negocio y mÃ©tricas en `EXECUTIVE_SUMMARY.md`.
- Licencia: MIT (ver `LICENSE` en el monorepo).
- Datos: ver `DATA_LICENSE` y `data_card.md`.
