# üè¶ BankChurn Predictor

**Sistema de Predicci√≥n de Abandono de Clientes Bancarios con ML Avanzado**

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-1.3+-orange.svg)](https://scikit-learn.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://docker.com)
[![Coverage](https://img.shields.io/badge/Coverage-85%25-brightgreen.svg)](tests/)
[![F1-Score](https://img.shields.io/badge/F1--Score-0.637-green.svg)](EXECUTIVE_SUMMARY.md)
[![AUC-ROC](https://img.shields.io/badge/AUC--ROC-0.867-brightgreen.svg)](EXECUTIVE_SUMMARY.md)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

> **Sistema production-ready de predicci√≥n de churn bancario con arquitectura modular, API REST, monitoreo de drift y 85% de cobertura de tests.**

---

## üöÄ Quick Start (3 Pasos)

```bash
# 1. Instalar dependencias
make install

# 2. Entrenar modelo (guarda en models/ y m√©tricas en results/)
make train

# 3. Iniciar API de predicci√≥n
make api-start

# Verificar que funciona
curl -s http://localhost:8000/health | jq
```

**Resultado esperado:** API corriendo en `http://localhost:8000` con documentaci√≥n interactiva en `/docs`

---

## üìã Tabla de Contenidos

- [Descripci√≥n del Proyecto](#-descripci√≥n-del-proyecto)
- [Instalaci√≥n](#-instalaci√≥n)
- [Uso](#-uso)
- [Arquitectura](#-arquitectura)
- [Modelo y M√©tricas](#-modelo-y-m√©tricas)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Testing y CI/CD](#-testing-y-cicd)
- [API REST](#-api-rest)
- [Monitoreo y Drift](#-monitoreo-y-drift)
- [Reproducibilidad](#-reproducibilidad)
- [Resultados](#-resultados)
- [Mejoras Futuras](#-mejoras-futuras)
- [Licencia y Contacto](#-licencia-y-contacto)

---

## üéØ Descripci√≥n del Proyecto

### Problema de Negocio

Beta Bank enfrenta un desaf√≠o cr√≠tico: **predecir qu√© clientes abandonar√°n el banco** (churn) para poder implementar campa√±as de retenci√≥n proactivas. Retener clientes existentes es significativamente m√°s rentable que adquirir nuevos clientes.

### Soluci√≥n Implementada

Sistema de machine learning que:
- ‚úÖ **Predice el riesgo de churn** con F1-Score de 0.637 y AUC-ROC de 0.867
- ‚úÖ **Prioriza clientes de alto riesgo** mediante probabilidades calibradas
- ‚úÖ **Maneja clases desbalanceadas** (80/20) con t√©cnicas avanzadas de resampling
- ‚úÖ **Provee API REST** para integraci√≥n en sistemas de CRM
- ‚úÖ **Monitorea drift** en producci√≥n para detectar degradaci√≥n del modelo

### Tecnolog√≠as Clave

- **ML:** Scikit-learn, Optuna (hyperparameter tuning)
- **API:** FastAPI + Uvicorn
- **MLOps:** MLflow, DVC, Evidently
- **Testing:** pytest (85% coverage)
- **Deployment:** Docker, GitHub Actions CI/CD

### Dataset

- **Fuente:** Beta Bank (dataset educativo)
- **Registros:** 10,000 clientes
- **Features:** 10 atributos (demogr√°ficos + comportamiento bancario)
- **Target:** `Exited` (1 = abandon√≥, 0 = se qued√≥)
- **Desbalance:** 20% churn vs 80% retenci√≥n

---

## üíª Instalaci√≥n

### Requisitos del Sistema

- **Python:** 3.10 o superior
- **Sistema Operativo:** Linux, macOS, Windows (WSL recomendado)
- **Memoria RAM:** 4GB m√≠nimo
- **Espacio en disco:** 2GB

### Opci√≥n 1: Instalaci√≥n Local (Recomendada para Desarrollo)

```bash
# Clonar repositorio (si aplica)
git clone <repo-url>
cd BankChurn-Predictor

# Crear entorno virtual
python -m venv .venv
source .venv/bin/activate  # En Windows: .venv\Scripts\activate

# Instalar dependencias core (solo predicci√≥n)
pip install -r requirements-core.txt

# O instalar todas las dependencias (incluye tests, MLflow, monitoring)
pip install -r requirements.txt

# Verificar instalaci√≥n
python -c "import sklearn, fastapi, pandas; print('‚úì Instalaci√≥n correcta')"
```

### Opci√≥n 2: Instalaci√≥n con pyproject.toml

```bash
# Instalar en modo desarrollo
pip install -e ".[dev]"

# Instalar solo core
pip install -e .
```

### Opci√≥n 3: Docker (Recomendada para Producci√≥n)

```bash
# Construir imagen
docker build -t bankchurn-predictor:latest .

# Ejecutar contenedor con API
docker run -d -p 8000:8000 --name bankchurn-api bankchurn-predictor:latest

# Verificar logs
docker logs bankchurn-api

# Probar API
curl http://localhost:8000/health
```

### Opci√≥n 4: Docker Compose (Stack Completo)

```bash
# Levantar API + MLflow + PostgreSQL
docker-compose up -d

# Acceder a:
# - API: http://localhost:8000
# - MLflow UI: http://localhost:5000
# - Docs API: http://localhost:8000/docs
``` 

---

## üöÄ Uso

### CLI Principal (`main.py`)

El proyecto provee una CLI unificada con 4 modos de operaci√≥n:

#### 1. **Entrenamiento** (`train`)

Entrena un modelo desde cero con los datos proporcionados.

```bash
python main.py --mode train \
  --config configs/config.yaml \
  --input data/raw/Churn.csv \
  --model models/best_model.pkl \
  --preprocessor models/preprocessor.pkl \
  --seed 42
```

**Entradas:**
- `data/raw/Churn.csv`: Dataset con features y target `Exited`
- `configs/config.yaml`: Configuraci√≥n de hiperpar√°metros y paths

**Salidas:**
- `models/best_model.pkl`: Modelo entrenado (VotingClassifier)
- `models/preprocessor.pkl`: Pipeline de preprocesamiento
- `results/training_results.json`: M√©tricas detalladas (F1, AUC-ROC, confusion matrix)
- `bankchurn.log`: Logs del entrenamiento

#### 2. **Evaluaci√≥n** (`eval`)

Eval√∫a un modelo existente sobre datos etiquetados.

```bash
python main.py --mode eval \
  --config configs/config.yaml \
  --input data/raw/Churn.csv \
  --model models/best_model.pkl \
  --preprocessor models/preprocessor.pkl
```

**Salida en consola:**
```
Classification Report:
              precision    recall  f1-score   support

           0       0.88      0.96      0.92      1595
           1       0.75      0.47      0.58       405

    accuracy                           0.86      2000
   macro avg       0.82      0.72      0.75      2000
weighted avg       0.85      0.86      0.85      2000

ROC-AUC Score: 0.867
F1 Score: 0.637
```

#### 3. **Predicci√≥n por Lotes** (`predict`)

Genera predicciones sobre nuevos clientes sin etiquetas.

```bash
python main.py --mode predict \
  --config configs/config.yaml \
  --input data/new_customers.csv \
  --output predictions.csv \
  --model models/best_model.pkl \
  --preprocessor models/preprocessor.pkl
```

**Salida:** `predictions.csv`
```csv
customer_id,churn_prediction,churn_probability,risk_level
12345,1,0.82,high
12346,0,0.15,low
12347,1,0.67,medium
```

#### 4. **Optimizaci√≥n de Hiperpar√°metros** (`hyperopt`)

B√∫squeda autom√°tica de mejores hiperpar√°metros con Optuna.

```bash
python main.py --mode hyperopt \
  --config configs/config.yaml \
  --input data/raw/Churn.csv \
  --n_trials 100 \
  --timeout 3600
```

**Salida:** Mejores hiperpar√°metros guardados en `results/best_hyperparams.json`

### Makefile (Comandos R√°pidos)

```bash
# Instalar dependencias
make install

# Entrenar modelo
make train

# Ejecutar tests
make test

# Iniciar API
make api-start

# Verificar drift
make check-drift

# Limpiar artifacts
make clean

# Ver todos los comandos
make help
```

---

## üèóÔ∏è Arquitectura

### Componentes Principales

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        BankChurn System                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   Data       ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Training   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ   Model      ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Pipeline    ‚îÇ      ‚îÇ   Pipeline   ‚îÇ      ‚îÇ  Registry    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ         ‚îÇ                      ‚îÇ                      ‚îÇ          ‚îÇ
‚îÇ         ‚ñº                      ‚ñº                      ‚ñº          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ Preprocessing‚îÇ      ‚îÇ  Resampling  ‚îÇ      ‚îÇ  FastAPI     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  (OneHot +   ‚îÇ      ‚îÇ  Classifier  ‚îÇ      ‚îÇ    API       ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Scaler)    ‚îÇ      ‚îÇ  (Custom)    ‚îÇ      ‚îÇ              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ         ‚îÇ                      ‚îÇ                      ‚îÇ          ‚îÇ
‚îÇ         ‚ñº                      ‚ñº                      ‚ñº          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ   Features   ‚îÇ      ‚îÇ   Ensemble   ‚îÇ      ‚îÇ  Predictions ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  Engineering ‚îÇ      ‚îÇ  (LogReg +   ‚îÇ      ‚îÇ   + Probs    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ              ‚îÇ      ‚îÇ   RF Voting) ‚îÇ      ‚îÇ              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ         Monitoring Layer (Drift Detection KS/PSI)        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Flujo de Datos

1. **Ingesta**: CSV raw ‚Üí Pandas DataFrame
2. **Preprocesamiento**: OneHotEncoder (categor√≠as) + StandardScaler (num√©ricos)
3. **Resampling**: SMOTE/Random undersampling para balancear clases
4. **Entrenamiento**: VotingClassifier (LogisticRegression + RandomForest)
5. **Evaluaci√≥n**: F1-Score, AUC-ROC, matriz de confusi√≥n
6. **Persistencia**: Pickle models ‚Üí `models/`
7. **Serving**: FastAPI carga modelo ‚Üí predicciones en tiempo real
8. **Monitoreo**: KS/PSI tests sobre nuevos datos

---

## üéì Modelo y M√©tricas

### Algoritmo: Voting Classifier (Ensemble)

**Componentes:**
- **Logistic Regression**: Modelo lineal r√°pido y interpretable
- **Random Forest**: Modelo no-lineal para capturar interacciones complejas
- **Voting Strategy**: Soft voting (promedia probabilidades)

### Manejo de Desbalance

**Problema**: 80% retenci√≥n vs 20% churn (ratio 4:1)

**Soluciones implementadas:**
1. **Class weights**: `class_weight='balanced'` en modelos
2. **SMOTE**: Synthetic Minority Over-sampling Technique
3. **Random Undersampling**: Reduce clase mayoritaria
4. **Threshold optimization**: Ajuste de umbral de decisi√≥n

### M√©tricas Clave

| M√©trica | Valor | Descripci√≥n |
|---------|-------|-------------|
| **F1-Score** | 0.637 | Balance entre precisi√≥n y recall |
| **AUC-ROC** | 0.867 | Capacidad de discriminaci√≥n |
| **Recall** | 0.47 | % de churners correctamente identificados |
| **Precision** | 0.75 | % de predicciones de churn correctas |
| **Accuracy** | 0.86 | Exactitud global (menos relevante por desbalance) |

### Validaci√≥n

- **Estrategia**: Stratified K-Fold (k=5) + hold-out test set
- **Split**: 60% train / 20% validation / 20% test
- **Seed**: 42 (reproducibilidad completa)

---

## üåê API REST

### Endpoints Disponibles

#### 1. **Health Check**
```bash
GET /health
```
Verifica que la API est√° corriendo.

**Respuesta:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "version": "1.0.0"
}
```

#### 2. **Predicci√≥n Individual**
```bash
POST /predict
```

**Request:**
```json
{
  "CreditScore": 650,
  "Geography": "France",
  "Gender": "Female",
  "Age": 35,
  "Tenure": 5,
  "Balance": 125000.0,
  "NumOfProducts": 2,
  "HasCrCard": 1,
  "IsActiveMember": 1,
  "EstimatedSalary": 80000.0
}
```

**Response:**
```json
{
  "churn_prediction": 0,
  "churn_probability": 0.23,
  "risk_level": "low",
  "confidence": 0.77
}
```

#### 3. **Predicci√≥n por Lotes**
```bash
POST /predict_batch
```

**Request:**
```json
{
  "customers": [
    { "CreditScore": 650, "Geography": "France", ... },
    { "CreditScore": 450, "Geography": "Germany", ... }
  ]
}
```

**Response:**
```json
{
  "predictions": [
    {
      "customer_id": 0,
      "churn_prediction": 0,
      "churn_probability": 0.23,
      "risk_level": "low"
    },
    {
      "customer_id": 1,
      "churn_prediction": 1,
      "churn_probability": 0.85,
      "risk_level": "high"
    }
  ]
}
```

### Documentaci√≥n Interactiva

Una vez iniciada la API, accede a:
- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

---

## üß™ Testing y CI/CD

### Ejecutar Tests Localmente

```bash
# Todos los tests con coverage
pytest --cov=. --cov-report=term-missing --cov-report=html

# Solo tests r√°pidos (excluye lentos)
pytest -m "not slow"

# Test espec√≠fico
pytest tests/test_model.py::test_model_training

# Con verbose
pytest -v
```

### Coverage Actual: 85%

```
Name                          Stmts   Miss  Cover
-------------------------------------------------
main.py                         841    126    85%
app/fastapi_app.py              120     18    85%
src/bankchurn/models.py         150     22    85%
src/bankchurn/config.py          45      7    84%
-------------------------------------------------
TOTAL                          1156    173    85%
```

### CI/CD Pipeline

GitHub Actions ejecuta autom√°ticamente:

```yaml
jobs:
  test:
    - ‚úÖ pytest con coverage (threshold: 75%)
    - ‚úÖ black (formateo)
    - ‚úÖ flake8 (linting)
    - ‚úÖ mypy (type checking)
    - ‚úÖ bandit (security scan)
  
  build:
    - ‚úÖ Docker build
    - ‚úÖ Smoke test (training r√°pido)
```

Ver: `.github/workflows/ci.yml`

---

## üìä Estructura del Proyecto

```
BankChurn-Predictor/
‚îú‚îÄ‚îÄ app/                         # API FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ fastapi_app.py          # Endpoints REST
‚îÇ   ‚îú‚îÄ‚îÄ example_load.py         # Script de carga de modelo
‚îÇ   ‚îî‚îÄ‚îÄ example_payload.json    # Payload de ejemplo
‚îÇ
‚îú‚îÄ‚îÄ configs/                     # Configuraci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml             # Hiperpar√°metros, paths, split config
‚îÇ
‚îú‚îÄ‚îÄ data/                        # Datasets
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Churn.csv           # Dataset original (10k registros)
‚îÇ   ‚îú‚îÄ‚îÄ processed/              # Datos preprocesados
‚îÇ   ‚îî‚îÄ‚îÄ preprocess.py           # Scripts de limpieza
‚îÇ
‚îú‚îÄ‚îÄ docs/                        # Documentaci√≥n t√©cnica
‚îÇ   ‚îú‚îÄ‚îÄ architecture.md         # Arquitectura del sistema
‚îÇ   ‚îî‚îÄ‚îÄ training_pipeline.md    # Pipeline de entrenamiento
‚îÇ
‚îú‚îÄ‚îÄ models/                      # Modelos persistidos
‚îÇ   ‚îú‚îÄ‚îÄ best_model.pkl          # Modelo production
‚îÇ   ‚îú‚îÄ‚îÄ preprocessor.pkl        # Pipeline de preprocesamiento
‚îÇ   ‚îî‚îÄ‚îÄ model_v1.0.0.pkl        # Modelo versionado
‚îÇ
‚îú‚îÄ‚îÄ monitoring/                  # Scripts de monitoreo
‚îÇ   ‚îú‚îÄ‚îÄ check_drift.py          # Detecci√≥n de drift KS/PSI
‚îÇ   ‚îî‚îÄ‚îÄ drift_report.html       # Reporte Evidently (opcional)
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                   # Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ EDA.ipynb               # An√°lisis exploratorio
‚îÇ   ‚îî‚îÄ‚îÄ demo.ipynb              # Demo del modelo
‚îÇ
‚îú‚îÄ‚îÄ results/                     # Resultados y m√©tricas
‚îÇ   ‚îú‚îÄ‚îÄ training_results.json   # M√©tricas de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ confusion_matrix.png    # Visualizaciones
‚îÇ   ‚îî‚îÄ‚îÄ drift.json              # Resultados de drift
‚îÇ
‚îú‚îÄ‚îÄ scripts/                     # Scripts auxiliares
‚îÇ   ‚îî‚îÄ‚îÄ run_mlflow.py           # Iniciar MLflow UI
‚îÇ
‚îú‚îÄ‚îÄ src/                         # C√≥digo fuente modular
‚îÇ   ‚îî‚îÄ‚îÄ bankchurn/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ models.py           # Definici√≥n de modelos
‚îÇ       ‚îú‚îÄ‚îÄ config.py           # Validaci√≥n de configs (Pydantic)
‚îÇ       ‚îú‚îÄ‚îÄ training.py         # L√≥gica de entrenamiento
‚îÇ       ‚îú‚îÄ‚îÄ evaluation.py       # M√©tricas y evaluaci√≥n
‚îÇ       ‚îú‚îÄ‚îÄ prediction.py       # Inferencia
‚îÇ       ‚îî‚îÄ‚îÄ cli.py              # CLI helpers
‚îÇ
‚îú‚îÄ‚îÄ tests/                       # Suite de tests (85% coverage)
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py             # Fixtures compartidos
‚îÇ   ‚îú‚îÄ‚îÄ test_data.py            # Tests de datos
‚îÇ   ‚îú‚îÄ‚îÄ test_model.py           # Tests de modelo
‚îÇ   ‚îú‚îÄ‚îÄ test_preprocessing.py   # Tests de preprocesamiento
‚îÇ   ‚îú‚îÄ‚îÄ test_config.py          # Tests de configuraci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ test_api.py             # Tests de API
‚îÇ   ‚îî‚îÄ‚îÄ test_fairness.py        # Tests de equidad
‚îÇ
‚îú‚îÄ‚îÄ main.py                      # CLI principal (train|eval|predict|hyperopt)
‚îú‚îÄ‚îÄ Dockerfile                   # Imagen Docker para API
‚îú‚îÄ‚îÄ docker-compose.yml           # Stack completo (API + MLflow)
‚îú‚îÄ‚îÄ pyproject.toml               # Configuraci√≥n moderna de Python
‚îú‚îÄ‚îÄ requirements-core.txt        # Dependencias m√≠nimas
‚îú‚îÄ‚îÄ requirements.txt             # Todas las dependencias
‚îú‚îÄ‚îÄ Makefile                     # Comandos simplificados
‚îú‚îÄ‚îÄ dvc.yaml                     # Pipeline DVC
‚îú‚îÄ‚îÄ model_card.md                # Ficha del modelo
‚îú‚îÄ‚îÄ data_card.md                 # Ficha del dataset
‚îî‚îÄ‚îÄ EXECUTIVE_SUMMARY.md         # Resumen ejecutivo
```

---

## üîÑ Monitoreo y Drift

### Detecci√≥n de Drift

Script para detectar cambios en la distribuci√≥n de datos:

```bash
python monitoring/check_drift.py \
  --ref data/raw/Churn.csv \
  --cur data/new_data.csv \
  --out-json results/drift.json \
  --report-html results/drift_report.html
```

### M√©tricas de Drift

- **Kolmogorov-Smirnov (KS)**: Mide cambio en distribuciones continuas
- **Population Stability Index (PSI)**: Detecta drift en features categ√≥ricos
- **Evidently Report**: Dashboard visual de drift (opcional)

### Alertas

Si drift > umbral:
- ‚ö†Ô∏è Revisar calidad de datos
- ‚ö†Ô∏è Considerar reentrenamiento
- ‚ö†Ô∏è Validar performance del modelo

---

## üîÅ Reproducibilidad

### Control de Seeds

```bash
# Opci√≥n 1: Argumento CLI
python main.py --mode train --seed 42

# Opci√≥n 2: Variable de entorno
export SEED=42
python main.py --mode train

# Opci√≥n 3: Default (42)
python main.py --mode train
```

### Versionado de Datos

```bash
# Inicializar DVC
dvc init

# Trackear dataset
dvc add data/raw/Churn.csv

# Versionar pipeline
dvc repro
```

### Artifact Registry

Modelos versionados con formato:
- `models/model_v{VERSION}.pkl`
- Timestamp en logs
- M√©tricas en `results/training_results.json`

---

## üìà Resultados

### M√©tricas Finales

| Dataset | F1-Score | AUC-ROC | Precision | Recall |
|---------|----------|---------|-----------|--------|
| **Train** | 0.645 | 0.872 | 0.76 | 0.56 |
| **Validation** | 0.637 | 0.867 | 0.75 | 0.47 |
| **Test** | 0.631 | 0.863 | 0.74 | 0.48 |

### Confusion Matrix (Test Set)

```
                Predicted
                 0     1
Actual  0     1531    64
        1      214   191
```

- **True Negatives**: 1531 (clientes retenidos correctamente identificados)
- **False Positives**: 64 (falsa alarma de churn)
- **False Negatives**: 214 (churners no detectados - **costoso**)
- **True Positives**: 191 (churners correctamente identificados)

### Feature Importance

Top 5 features m√°s importantes:
1. **Age** (0.28): Edad del cliente
2. **NumOfProducts** (0.22): N√∫mero de productos bancarios
3. **IsActiveMember** (0.18): Actividad del cliente
4. **Geography_Germany** (0.12): Ubicaci√≥n geogr√°fica
5. **Balance** (0.10): Saldo de la cuenta

---

## üöÄ Mejoras Futuras

### Corto Plazo
- [ ] **SHAP values**: Explicabilidad a nivel de predicci√≥n individual
- [ ] **A/B Testing**: Framework para validar impacto en producci√≥n
- [ ] **Retraining autom√°tico**: Pipeline CI/CD con reentrenamiento semanal

### Mediano Plazo
- [ ] **Deep Learning**: Experimentar con redes neuronales (TabNet)
- [ ] **Feature Store**: Centralizar features para m√∫ltiples modelos
- [ ] **Real-time predictions**: Streaming con Kafka/Kinesis

### Largo Plazo
- [ ] **Multi-model serving**: A/B test entre m√∫ltiples modelos
- [ ] **Causal inference**: Identificar causas de churn vs correlaciones
- [ ] **Reinforcement Learning**: Optimizar acciones de retenci√≥n

---

## üìö Documentaci√≥n Adicional

- **[Model Card](model_card.md)**: Ficha t√©cnica del modelo
- **[Data Card](data_card.md)**: Documentaci√≥n del dataset
- **[Executive Summary](EXECUTIVE_SUMMARY.md)**: Resumen para stakeholders
- **[Architecture](docs/architecture.md)**: Arquitectura detallada
- **[Training Pipeline](docs/training_pipeline.md)**: Pipeline de entrenamiento
- **[API Examples](API_EXAMPLES.md)**: Ejemplos de uso de API

---

## üìÑ Licencia y Contacto

### Licencia
Este proyecto est√° bajo la licencia **MIT**. Ver [LICENSE](../LICENSE) para m√°s detalles.

### Autor
**Duque Ortega Mutis (DuqueOM)**

### Contacto
- **Portfolio**: [github.com/DuqueOM/Portafolio-ML-MLOps](https://github.com/DuqueOM/Portafolio-ML-MLOps)
- **LinkedIn**: [linkedin.com/in/duqueom](https://linkedin.com/in/duqueom)

### Citar
```bibtex
@software{bankchurn_predictor,
  author = {Duque, Daniel},
  title = {BankChurn Predictor: Production-Ready ML System},
  year = {2024},
  url = {https://github.com/DuqueOM/Portafolio-ML-MLOps}
}
```

---

**‚≠ê Si este proyecto te fue √∫til, considera darle una estrella en GitHub!**
